import pandas as pd
import os
from sqlalchemy import engine
import psycopg2
import openai
import signal
from ast import literal_eval
from type1tosql import tp1totp0, reconstruct_type0, tp0tosentences
from type2tosql import tp2totp1, reconstruct_type1
from Levenshtein import distance as lev
from c3_utils import get_schema, c3_e2e
from tenacity import (
    retry,
    stop_after_attempt,
    wait_random_exponential,
    retry_if_exception_type
)  # for exponential backoff

#generated by chatgpt
administrators = list(set([
    "System Administrator",
    "Network Administrator",
    "Database Administrator",
    "Linux Administrator",
    "Windows Administrator",
    "Cloud Administrator",
    "Salesforce Administrator",
    "Exchange Administrator",
    "SharePoint Administrator",
    "Active Directory Administrator",
    "Security Administrator",
    "Database Security Administrator",
    "Application Administrator",
    "Web Administrator",
    "Storage Administrator",
    "Virtualization Administrator",
    "SAP Administrator",
    "HR Administrator",
    "Financial Administrator",
    "School Administrator",
    "Healthcare Administrator",
    "Hospital Administrator",
    "Office Administrator",
    "Project Administrator",
    "CRM Administrator",
    "Database Developer/Administrator",
    "Education Administrator",
    "Event Administrator",
    "System Integration Administrator"
]))

common_names = [
    "John",
    "Mary",
    "Michael",
    "Jennifer",
    "James",
    "Sarah",
    "David",
    "Jessica",
    "Robert",
    "Elizabeth",
    "William",
    "Emily",
    "Joseph",
    "Ashley",
    "Christopher",
    "Amanda",
    "Daniel",
    "Megan",
    "Matthew",
    "Rachel"
]

german_names = [
    "Friedrich", "Gisela", "Dieter", "Helga", "Klaus",
    "Ingrid", "Jürgen", "Ursula", "Rainer", "Brigitte",
    "Gunter", "Renate", "Horst", "Hannelore", "Manfred",
    "Gertrud", "Heinrich", "Lieselotte", "Wolfgang", "Elfriede",
    "Gerhard", "Traudl", "Eberhard", "Mechthild", "Siegfried",
    "Brunhilde", "Günther", "Irmgard", "Hartmut", "Adelheid"
]


interns = list(set([
    "Marketing Intern",
    "Software Development Intern",
    "Graphic Design Intern",
    "Data Analyst Intern",
    "Human Resources Intern",
    "Social Media Intern",
    "Business Development Intern",
    "Content Writing Intern",
    "Research Intern",
    "Finance Intern",
    "Product Management Intern",
    "IT Support Intern",
    "Video Production Intern",
    "Sales Intern",
    "UXUI Design Intern",
    "Public Relations Intern",
    "Environmental Science Intern",
    "Supply Chain Intern",
    "Event Planning Intern",
    "Engineering Intern",
    "Healthcare Administration Intern",
    "Legal Intern",
    "Nonprofit Management Intern",
    "Architecture Intern",
    "Cybersecurity Intern",
    "Art Curator Intern",
    "Journalism Intern",
    "Culinary Arts Intern",
    "Fashion Merchandising Intern",
    "Sports Management Intern"
]))
interns = [st.replace(' ', '_') for st in interns]
administrators = [st.replace(' ', '_') for st in administrators]

#TODO: for now, we hardcode the retrieval of roles from the database.
#this would also come from postgres.
def get_dbroles(db_details):
    full_lst = administrators + interns
    return full_lst

#TODO: for now, we'll hardcode it. But this needs to come from postgres.
def get_tbl_schema(db_details):
    #for now, let's just hardcode it
    return str(['supplier', 'customer', 'lineitem','region',
            'orders', 'partsupp', 'part', 'nation'])

class MyTimeoutException(Exception):
    pass

#register a handler for the timeout
def handler(signum, frame):
    print("Waited long enough!")
    raise MyTimeoutException("STOP")
    
@retry(retry=retry_if_exception_type(Exception), wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))
def get_response(chat, temp_val, timeout=30):
    
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=chat,
        temperature=temp_val
    )
    chat_response = response["choices"][0]["message"]["content"]
    print("Received response: {}".format(chat_response))
    return chat_response

def schema_to_st(db_schema : dict):
    schema = ""
    for tab, cols in db_schema.items():
        schema += '# ' + tab + ' ( '
        for i, col in enumerate(cols):
            schema += col
            schema += ', '
        schema = schema[:-2] + ' )\n'
    
    return schema

def find_nearest_lev(response, db_roles):
    min_lev = lev(response, db_roles[0])
    out_min = db_roles[0]
    for r in db_roles:
        if lev(response, r) < min_lev:
            min_lev = lev(response, r)
            out_min = r
    print("Minimum was: {}, {}".format(min_lev, out_min))
    return out_min
    

def parse_role(response : str, db_roles : list, alt_sim='levenshtein'):
    lst = [r for r in db_roles if r in response]
    if len(lst) > 1:
        print("Detected more than one role. Choosing First: {}".format(lst))
    
    if lst == []:
        print("ChatGPT failed to pick term from list: {}, {}".format(response, db_roles))
        if alt_sim == 'levenshtein':
            return find_nearest_lev(response, db_roles)
    
    return lst[0]

def t3sent_to_t2(role_st : str, db_roles : list, alt_sim='levenshtein'):
    chat = [{'role' : 'system', 'content' : 'You are a helpful assistant.'}]
    prompt = '### Choose the role from the list that best fits the given role description. \n ###  Roles: \n ' + str(db_roles)
    prompt += '\n### Description: \n ' + role_st
    chat += [{'role' : 'user', 'content' : prompt}]
    role_resp = get_response(chat, 0.0)
    out_role = parse_role(role_resp, db_roles)
    return out_role

def tp3totp2(tp3acmpath, outdir, outname, max_rows=None, max_cols=None):
    if not os.path.exists(outdir):
        os.mkdir(outdir)
    df = pd.read_csv(tp3acmpath)
    db_roles = get_dbroles({})
    tp3roles = df['Role'].tolist()
    
    for i,r in enumerate(tp3roles):
        outfile = outname + '_tp3totp2row' + str(i) + '.txt'
        outfile = os.path.join(outdir, outfile)
        if os.path.exists(outfile):
            continue
        
        if 'CREATE USER' in r:
            final_sent = r
        else:
            final_sent = t3sent_to_t2(r, db_roles)
        
        with open(outfile, 'w+') as fh:
            print(final_sent, file=fh)
    

def reconstruct_type2(tp3_path, new_name):
    #we also want to store the mappings of privileges to type 1 sentences.
    #this will help later.
    acm_path = tp3_path
    df = pd.read_csv(acm_path)
    new_dct = {}
    tp3totp2 = {}
    
    for c in df.columns:
        if c == 'Role':
            continue
        new_dct[c] = df[c].tolist()
    
    new_roles = []
    for i,r in enumerate(df['Role'].tolist()):
        outfile = new_name + '_tp3totp2row' + str(i) + '.txt'
        with open(outfile, 'r') as fh:
            new_role_st = fh.read()
        
        new_role_st.replace('\n', '')
        new_roles.append(new_role_st)
        tp3totp2[r] = new_role_st
    
    new_dct['Role'] = new_roles
    new_df = pd.DataFrame(new_dct)
    new_df.to_csv(new_name + '.csv', index=False)
    with open(new_name + '_tp2totp3.json', 'w+') as fh:
        print(tp3totp2, file=fh)

#use C3 to generate sentences
def gen_tp2sql(new_tp2acmpath):
    #TODO: this method heavily reuses code in type1tosql.py.
    #we may want to refactor this.
    tp2_noext = new_tp2acmpath.split('.')[:-1]
    tp2_outname = '.'.join(tp2_noext) + '_totp1'
    tp2totp1(new_tp2acmpath, '.', tp2_outname)
    reconstruct_type1(new_tp2acmpath, tp2_outname)
    
    new_tp1acmpath = tp2_outname + '.csv'
    tp1_outname = tp2_outname + '_totp0'
    tp1totp0(new_tp1acmpath, tp1_outname)
    reconstruct_type0(new_tp1acmpath, tp1_outname)
    tp0acmpath = tp1_outname + '.csv'
    
    sentences = tp0tosentences(tp0acmpath)
    print(sentences)
    
    #generate the SQL files on disk for these sentences by running c3 end-to-end
    #this will return a dictionary of each sentence to its query
    nl2sql = c3_e2e(sentences, outdir='c3newtp2_raw', inprefix='c3newtp2_', outprefix='c3newtp2_complete', compdir='c3newtp2complete', sql_prefix='c3sql_newtp2', sqldir='c3newtp2sql', dctname='c3newtp2_nl2sql.json')
    
    return nl2sql

if __name__=='__main__':
    tp3totp2('../acmgen/dacview_test_type3acm.csv', 'dacview_test_tp3totp2_all', 'dacview_tp3tp2')
    reconstruct_type2('../acmgen/dacview_test_type3acm.csv', 'dacview_test_tp3totp2_all/dacview_tp3tp2')
    gen_tp2sql('dacview_test_tp3totp2_all/dacview_tp3tp2.csv')

